package com.devonfw.module.kafka.config;

import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.util.Properties;

import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.EnvironmentAware;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.support.PropertySourcesPlaceholderConfigurer;
import org.springframework.core.env.Environment;
import org.springframework.util.ResourceUtils;

/**
 * class reads consumer properties from application.properties as part of POC In actual project Implementation move
 * these to separate location Basic minimum set of properties are considered for POC Current configuration supports
 * plaintext protocol and not SSL * @author pravbhav
 *
 */
@Configuration

public class KafkaConsumerProperties{

  @Value("${kafka.consumer.session.timeout.ms}")
  private String timeoutms;

  @Value("${kafka.consumer.group.id}")
  private String groupId;

  @Value("${kafka.consumer.buffer.memory}")
  private String buffermemory;

  @Value("${kafka.consumer.key.deserializer}")
  private String keydeserializer;

  @Value("${kafka.consumer.value.deserializer}")
  private String valuedeserializer;

  @Value("${kafka.consumer.topic}")
  private String topic;

  @Value("${kafka.consumer.client.id}")
  private String clientId;

  @Value("${kafka.consumer.bootstrap.servers}")
  private String bootstrapservers;

  @Value("${kafka.consumer.enable.auto.commit}")
  private String autocommit;

  @Value("${kafka.consumer.auto.commit.interval}")
  private int autocommitInterval;
  public String getKeydeserializer() {

	  //return environment.getProperty("kafka.consumer.key.deserializer").trim();
	  return this.keydeserializer;

  }

  public void setKeydeserializer(String keydeserializer) {

    this.keydeserializer = keydeserializer;
  }

  public String getValuedeserializer() {

	 return  this.keydeserializer ;
	  //return environment.getProperty("kafka.consumer.value.deserializer").trim();

  }

  public void setValuedeserializer(String valuedeserializer) {

    this.valuedeserializer = valuedeserializer;
  }



  /*
   * Return the instance of Properties class for Consumer object to be created properties values currently loaded from
   * application properties
   */
  public Properties getProperties() {

    Properties prop = new Properties();
  //  prop.put("consumer.enable.auto.commit", this.getAutocommit());
  //  prop.put("auto.commit.interval.ms", this.getAutocommitInterval());
    prop.put("session.timeout.ms", this.getTimeoutms());
    prop.put("group.id", this.getGroupId());
    prop.put("key.deserializer", this.getKeydeserializer());
    prop.put("value.deserializer", this.getValuedeserializer());
    prop.put("client.id", this.getClientId());
    prop.put("bootstrap.servers", this.getBootstrapservers());
    return prop;

  }



  /*
   * Return properties object for producer to be created.
   *
   */

  public void setProperties(Properties prop )
  {

	    setClientId(prop.getProperty("kafka.producer.clientId"));
	    setBootstrapservers(prop.getProperty("kafka.producer.bootstrapservers"));
	    prop.setProperty("bootstrap.servers", getBootstrapservers());
	    setAcks(prop.getProperty("kafka.producer.acks") );
	    setRetries(prop.getProperty("kafka.producer.retries"));
	    setBatchsize(prop.getProperty("kafka.producer.batchsize"));
	    setLingerms( prop.getProperty("kafka.producer.lingerms"));
	    setBuffermemory( prop.getProperty("kafka.producer.buffermemory"));
	    setKeyserializer( prop.getProperty("kafka.producer.keyserializer"));
	    setValueserializer( prop.getProperty("kafka.producer.valueserializer"));
  }

  /**
   *
   * @return kafka Producer properties
   */
  public Properties getProperties() {

    Properties prop = new Properties();
    Properties pr = new Properties() ;
    InputStream in = null;
    File file = null ;
    try {
	        file = ResourceUtils.getFile("classpath:kafka-consumer.properties");
	        in = new FileInputStream(file);
	        prop.load(in);
	        setProperties(prop);
			in.close();
	} catch (IOException e) {
		 e.printStackTrace();
		 return new Properties();
	}finally {

	}
    pr.setProperty("session.timeout.ms", getClientId());
    pr.setProperty("bootstrap.servers", getBootstrapservers());
    pr.setProperty("group.id", getGroupId());
    pr.setProperty("buffer.memory", getBuffermemory());
    pr.setProperty("key.deserializer", getKeydeserializer());
    pr.setProperty("value.deserializer", getValuedeserializer());
    /*
    prop.setProperty("client.id", "console-producer");
    prop.setProperty("bootstrap.servers", "10.76.3.49:9092");
    prop.setProperty("acks", "all");
    prop.setProperty("retries", "0");
    prop.setProperty("batch.size", "16384");
    prop.setProperty("linger.ms", "1");
    prop.setProperty("buffer.memory", "33554432");
    prop.setProperty("key.serializer", "com.devonfw.module.kafka.config.KafkaMessageSerializer");
    prop.setProperty("value.serializer", "com.devonfw.module.kafka.config.KafkaMessageSerializer");
*/
    return pr;

  }






  /**
   * @return topic
   */
  public String getTopic() {
   // return environment.getProperty("kafka.consumer.topic").trim();
    return this.topic ;

  }

  /**
   * @param topic new value of {@link #gettopic}.
   */
  public void setTopic(String topic) {
    this.topic = topic;
  }

  /**
   * @return clientId
   */
  public String getClientId() {

	  return this.clientId ;

    //return environment.getProperty("kafka.consumer.client.id").trim();
  }

  /**
   * @param clientId new value of {@link #getclientId}.
   */
  public void setClientId(String clientId) {

    this.clientId = clientId;
  }

  /**
   * @return bootstrapservers
   */
  public String getBootstrapservers() {
	  //return environment.getProperty("kafka.consumer.bootstrap.servers").trim();
     return this.bootstrapservers ;
  }

  /**
   * @param bootstrapservers new value of {@link #getbootstrapservers}.
   */
  public void setBootstrapservers(String bootstrapservers) {
    this.bootstrapservers = bootstrapservers;
  }

  /**
   * @return buffermemory
   */
  public String getBuffermemory() {

    // return environment.getProperty("kafka.consumer.buffer.memory").trim();
	 return this.buffermemory ;

  }

  /**
   * @param buffermemory new value of {@link #getbuffermemory}.
   */
  public void setBuffermemory(String buffermemory) {

    this.buffermemory = buffermemory;
  }

  /**
   * @return autocommit
   */
  public String getAutocommit() {

  //  return environment.getProperty("kafka.consumer.enable.auto.commit").trim();
	  return this.autocommit ;
  }

  /**
   * @param autocommit new value of {@link #getautocommit}.
   */
  public void setAutocommit(String autocommit) {

    this.autocommit = autocommit;
  }

  /**
   * @return autocommitInterval
   */
  public int getAutocommitInterval() {

   // String interval = environment.getProperty("kafka.consumer.auto.commit.interval");

	  return this.autocommitInterval ;
    // int inval = Integer.parseInt(interval);
    // return inval ;
  }

  /**
   * @param autocommitInterval new value of {@link #getautocommitInterval}.
   */
  public void setAutocommitInterval(int autocommitInterval) {

    this.autocommitInterval = autocommitInterval;
  }

  /**
   * @param timeoutms new value of {@link #gettimeoutms}.
   */
  public void setTimeoutms(String timeoutms) {

    this.timeoutms = timeoutms;
  }

  /**
   * @param groupId new value of {@link #getgroupId}.
   */
  public void setGroupId(String groupId) {

    this.groupId = groupId;
  }

  /**
   * @return timeoutms
   */
  public String getTimeoutms() {

    // return environment.getProperty("kafka.consumer.session.timeout.ms").trim();
	  return this.timeoutms ;
  }

  /**
   * @return groupId
   */
  public String getGroupId() {

    //return environment.getProperty("kafka.consumer.group.id").trim();
	  return this.groupId ;
  }

}
